import { logger } from '../utils/logger'
import { parseAIJsonString } from '../utils'
import { BatchProcessor } from '../utils/BatchProcessor'

export class AIAnalyzer {
  /**
   * @param {object} [options]
   * @param {boolean} [options.logToConsole=true] â€” æ˜¯å¦æ‰“å°åˆ°æ§åˆ¶å°
   */
  constructor ({
                 url,
                 model,
                 systemPrompt,
                 logToConsole,
                 headers = {},
                 otherOptions = {},
                 batchSize = 5,
                 maxRetry = 1,
                 maxMessages = 20,
                 maxQueueSize = 5,
                 analyzeTtl = 24 * 3600 * 1000,
                 storageKey = 'PerfSDK_lastAnalyzeTime',
                 onSuccess,
                 environmentInfo
               } = {}) {
    this.systemPrompt = systemPrompt
    this.logToConsole = logToConsole
    this.maxRetry = maxRetry
    this.maxMessages = maxMessages
    this.messages = []

    // å­˜å‚¨å¤šè½®å¯¹è¯çš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå…ˆå°è¯•ä» sessionStorage æ¢å¤
    const stored = sessionStorage.getItem('ai_analyzer_message')
    if (stored) {
      try {
        this.messages = JSON.parse(stored)
      } catch {
        this.messages = []
      }
    } else {
      this.messages = []
    }

    // å¦‚æœ messages é‡Œæ²¡æœ‰ system æç¤ºï¼Œåˆ™æ’å…¥
    if (!this.messages.find(m => m.role === 'system')) {
      this.messages.unshift({
        role: 'system',
        content: this.systemPrompt || ''
      })
      sessionStorage.setItem('ai_analyzer_message', JSON.stringify(this.messages))
    }

    this.processor = new BatchProcessor({
      batchSize,
      maxQueueSize,
      ttl: analyzeTtl,
      storageKey,
      storageType: 'sessionStorage',
      maxRetry,
      processBatchFn: async (batch) => {
        // batch ä¸­æ˜¯ array of snapshots
        logger.debug('å‘èµ· AI è¯·æ±‚ï¼Œå‚æ•°ï¼š', {
          pages: batch,
          environment: environmentInfo
        })

        // å…ˆæ„é€ è¦å‘é€çš„ user-message å¯¹è±¡
        const userMessage = {
          role: 'user',
          content: JSON.stringify({
            pages: batch,
            environment: environmentInfo
          })
        }

        // å…ˆæ’å…¥çœŸå® user æ¶ˆæ¯ï¼Œå¹¶è£å‰ªæœ¬åœ°å†å²
        // this.messages.push(userMessage)
        this._trimMessageHistory()

        // å‘èµ· fetch è¯·æ±‚
        const res = await fetch(url, {
          method: 'POST',
          headers: {
            'Content-Type': headers.ContentType || 'application/json',
            Authorization: headers.token || ''
          },
          body: JSON.stringify({
            model: model,
            messages: [
              ...this.messages,
              userMessage
            ],
            ...otherOptions
          })
        })

        if (!res.ok) {
          throw new Error(`AI æ¥å£è¿”å›çŠ¶æ€ ${res.status}`)
        }

        const result = await res.json()
        logger.debug('AI å“åº”åŸå§‹ï¼š', res, result)

        // è§£æ AI è¿”å›å†…å®¹ï¼Œå¹¶æ¨å…¥ messages
        const rawContent = result.choices?.[0]?.message?.content || ''
        let parsedContent
        try {
          parsedContent = parseAIJsonString(rawContent)
        } catch (err) {
          logger.error('è§£æ AI è¿”å› JSON å¤±è´¥ï¼ŒåŸå§‹å†…å®¹ï¼š', rawContent, err)
          parsedContent = rawContent // å³ä½¿è§£æå¤±è´¥ï¼Œä¹Ÿä¿ç•™åŸå§‹å­—ç¬¦ä¸²
        }

        // æ‰“å°åˆ°æ§åˆ¶å°
        if (this.logToConsole) {
          console.group('%c ğŸ“Š æ€§èƒ½åˆ†æç»“æœ', 'color: #409EFF; font-weight: bold;')
          console.log(parsedContent)
          console.groupEnd()
        }

        this.messages.push(userMessage)
        // æŠŠ assistant çš„å›å¤ä¹Ÿå­˜å‚¨åœ¨ messages
        this.messages.push({
          role: 'assistant',
          content: JSON.stringify(parsedContent)
        })
        sessionStorage.setItem('ai_analyzer_message', JSON.stringify(this.messages))

        onSuccess(rawContent)
      }
    })
  }

  /**
   * è®¢é˜… DataCache çš„ enqueue äº‹ä»¶ï¼Œå½“æœ‰æ–°å¿«ç…§æ—¶ï¼Œå…¥é˜Ÿ
   * @param {DataCache} dataCache
   */
  subscribe (dataCache) {
    if (!dataCache || typeof dataCache.enqueue !== 'function') {
      throw new Error('[Reporter] subscribe éœ€è¦ä¼ å…¥ DataCache å®ä¾‹')
    }
    dataCache.onEnqueue = (snapshot) => {
      this.processor.enqueue({ key: snapshot.pageName, ...snapshot })
    }
  }

  /**
   * ç®€åŒ–ç‰ˆè£å‰ªï¼šåªä¿ç•™é¦–æ¡ system + æœ€è¿‘ maxMessages æ¡
   */
  _trimMessageHistory () {
    const max = this.maxMessages
    const msg = this.messages
    // å¦‚æœæ€»é‡ â‰¤ system(1) + maxï¼Œåˆ™ä¸ç”¨è£å‰ª
    if (msg.length <= max + 1) {
      return this.messages
    }
    const systemMsg = msg[0]
    // å–å°¾éƒ¨æœ€å max æ¡
    const tail = msg.slice(-max)
    this.messages = [systemMsg, ...tail]
    // æŒä¹…åŒ–åˆ° sessionStorage
    sessionStorage.setItem('ai_analyzer_message', JSON.stringify(this.messages))
    return [
      systemMsg,
      {
        role: 'system',
        content: `æ³¨æ„ï¼šä»¥ä¸‹ä»…ä¿ç•™æœ€è¿‘ ${this.maxMessages} æ¡å¯¹è¯ï¼Œä¹‹å‰å†…å®¹å·²è¢«çœç•¥ã€‚`
      },
      ...tail
    ]
  }

  destroy () {
    this.processor.destroy()
  }
}
